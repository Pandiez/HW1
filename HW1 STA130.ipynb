{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9f42519",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n           0\n",
       "id              1\n",
       "name            0\n",
       "gender          0\n",
       "species         0\n",
       "birthday        0\n",
       "personality     0\n",
       "song           11\n",
       "phrase          0\n",
       "full_id         0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b563b7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1\n",
      "Number of columns: 11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your dataset is in a CSV file, replace 'your_dataset.csv' with the actual file path\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Or, if you have your dataset as a DataFrame object named `df`\n",
    "df = pd.DataFrame({\n",
    "    'row_n': [0],\n",
    "    'id': [1],\n",
    "    'name': [0],\n",
    "    'gender': [0],\n",
    "    'species': [0],\n",
    "    'birthday': [0],\n",
    "    'personality': [0],\n",
    "    'song': [11],\n",
    "    'phrase': [0],\n",
    "    'full_id': [0],\n",
    "    'url': [0]\n",
    "})\n",
    "\n",
    "# Print the number of rows and columns\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214b5018",
   "metadata": {},
   "source": [
    "Based on the context of my dataset, observations refer to the individual entries or records in a dataset. Each observation represents a single data point or instance within the dataset.\n",
    "Observations could represent individual entities or objects, such as rows in a table. \n",
    "Variables are the different characteristics, attributes, or properties that are recorded for each observation. These are the columns in a dataset that describe various aspects or features of the observations.\n",
    "Each variable represents a different type of information collected for each observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae6db070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame with some example data\n",
    "data = {\n",
    "    'row_n': [0, 1, 2, 3],\n",
    "    'id': [1, 2, 3, 4],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'gender': ['Female', 'Male', 'Male', 'Female'],\n",
    "    'species': ['Cat', 'Dog', 'Cat', 'Dog'],\n",
    "    'birthday': ['1990-01-01', '1985-06-15', '1992-12-10', '1995-07-20'],\n",
    "    'personality': ['Jovial', 'Calm', 'Brave', 'Calm'],\n",
    "    'song': [11, 12, 11, 13],\n",
    "    'phrase': ['Hello', 'Goodbye', 'Hello', 'Hey'],\n",
    "    'full_id': ['1-1', '2-2', '3-3', '4-4'],\n",
    "    'url': ['http://example.com/1', 'http://example.com/2', 'http://example.com/3', 'http://example.com/4']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54dbbcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Summary:\n",
      "          row_n        id       song\n",
      "count  4.000000  4.000000   4.000000\n",
      "mean   1.500000  2.500000  11.750000\n",
      "std    1.290994  1.290994   0.957427\n",
      "min    0.000000  1.000000  11.000000\n",
      "25%    0.750000  1.750000  11.000000\n",
      "50%    1.500000  2.500000  11.500000\n",
      "75%    2.250000  3.250000  12.250000\n",
      "max    3.000000  4.000000  13.000000\n"
     ]
    }
   ],
   "source": [
    "numerical_summary = df.describe()\n",
    "print(\"Numerical Summary:\")\n",
    "print(numerical_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d3a8188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gender Counts:\n",
      "gender\n",
      "Female    2\n",
      "Male      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Species Counts:\n",
      "species\n",
      "Cat    2\n",
      "Dog    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Personality Counts:\n",
      "personality\n",
      "Calm      2\n",
      "Jovial    1\n",
      "Brave     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get counts for 'gender' column\n",
    "gender_counts = df['gender'].value_counts()\n",
    "print(\"\\nGender Counts:\")\n",
    "print(gender_counts)\n",
    "\n",
    "# Get counts for 'species' column\n",
    "species_counts = df['species'].value_counts()\n",
    "print(\"\\nSpecies Counts:\")\n",
    "print(species_counts)\n",
    "\n",
    "# Get counts for 'personality' column\n",
    "personality_counts = df['personality'].value_counts()\n",
    "print(\"\\nPersonality Counts:\")\n",
    "print(personality_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e687f965",
   "metadata": {},
   "source": [
    "df.shape:\n",
    "\n",
    "Returns the total number of rows and columns in the dataset.\n",
    "Example: df.shape might return (4, 11), meaning 4 rows and 11 columns.\n",
    "\n",
    "df.describe():\n",
    "\n",
    "By default, only provides summaries for numeric columns (like integers and floats).\n",
    "The \"count\" in df.describe() shows the number of non-missing (non-NaN) values in each numeric column.\n",
    "If a numeric column has missing values, the count will be less than the total number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "411f705c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size (rows, columns): (4, 4)\n",
      "\n",
      "Summary of Numeric Columns:\n",
      "             id  song\n",
      "count  3.000000   3.0\n",
      "mean   2.666667  12.0\n",
      "std    1.527525   1.0\n",
      "min    1.000000  11.0\n",
      "25%    2.000000  11.5\n",
      "50%    3.000000  12.0\n",
      "75%    3.500000  12.5\n",
      "max    4.000000  13.0\n",
      "\n",
      "Summary of All Columns:\n",
      "              id   name  gender  song\n",
      "count   3.000000      4       4   3.0\n",
      "unique       NaN      4       2   NaN\n",
      "top          NaN  Alice  Female   NaN\n",
      "freq         NaN      1       2   NaN\n",
      "mean    2.666667    NaN     NaN  12.0\n",
      "std     1.527525    NaN     NaN   1.0\n",
      "min     1.000000    NaN     NaN  11.0\n",
      "25%     2.000000    NaN     NaN  11.5\n",
      "50%     3.000000    NaN     NaN  12.0\n",
      "75%     3.500000    NaN     NaN  12.5\n",
      "max     4.000000    NaN     NaN  13.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a DataFrame with missing values\n",
    "data = {\n",
    "    'id': [1, np.nan, 3, 4],               # Numeric column with a missing value\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David'],  # Non-numeric column\n",
    "    'gender': ['Female', 'Male', 'Male', 'Female'], # Non-numeric column\n",
    "    'song': [11, 12, np.nan, 13]           # Numeric column with a missing value\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Get the size of the dataset\n",
    "print(\"Dataset size (rows, columns):\", df.shape)\n",
    "\n",
    "# Describe numeric columns\n",
    "numeric_summary = df.describe()\n",
    "print(\"\\nSummary of Numeric Columns:\")\n",
    "print(numeric_summary)\n",
    "\n",
    "# Describe all columns, including non-numeric\n",
    "full_summary = df.describe(include='all')\n",
    "print(\"\\nSummary of All Columns:\")\n",
    "print(full_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd0a8bb",
   "metadata": {},
   "source": [
    "I have learned that the direct information stored in the object are provided by attributes (df.shape).\n",
    "On the other hand, Methods (df.describe()) perform actions or computations and take parameters for customization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9f55c9",
   "metadata": {},
   "source": [
    "Summary:\n",
    "\n",
    "Dataset Overview: You provided a dataset with various columns (like id, name, gender, etc.) and some missing values. You wanted to understand how to get the number of rows and columns, and how to summarize the data.\n",
    "\n",
    "Meaning of Observations and Variables: You asked for definitions of \"observations\" (rows of data) and \"variables\" (columns of data) in a dataset.\n",
    "\n",
    "Using df.describe() and value_counts(): You wanted examples of using df.describe() to get summaries of numeric columns and df['column'].value_counts() to count unique values in categorical columns.\n",
    "\n",
    "Handling Non-numeric Data and Missing Values: You asked why there might be differences between the dataset size (df.shape) and what df.describe() reports, especially when there are missing values or non-numeric columns.\n",
    "\n",
    "Attributes vs. Methods: You wanted to know the difference between an \"attribute\" (like df.shape, which represents stored data) and a \"method\" (like df.describe(), which performs an action or computation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84636104",
   "metadata": {},
   "source": [
    "Chatbox Link:https://chatgpt.com/share/66e35a16-90c4-800e-9f52-f79ec8faae05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13f7520",
   "metadata": {},
   "source": [
    "Count:\n",
    "Definition: The number of non-missing (non-NaN) values in the column.\n",
    "Purpose: Indicates how many values are available for analysis.\n",
    "\n",
    "Mean:\n",
    "Definition: The average of the values in the column.\n",
    "Purpose: Provides a measure of the central tendency of the data.\n",
    "\n",
    "Std (Standard Deviation):\n",
    "Definition: A measure of the amount of variation or dispersion in the values.\n",
    "Purpose: Indicates how spread out the values are from the mean.\n",
    "\n",
    "Min:\n",
    "Definition: The smallest value in the column.\n",
    "Purpose: Shows the lower end of the data range.\n",
    "\n",
    "25% (25th Percentile or First Quartile):\n",
    "Definition: The value below which 25% of the data falls.\n",
    "Purpose: Indicates the lower end of the middle 50% of the data.\n",
    "\n",
    "50% (50th Percentile or Median):\n",
    "Definition: The middle value when the data is sorted in ascending order.\n",
    "Purpose: Provides the central value of the data set.\n",
    "\n",
    "75% (75th Percentile or Third Quartile):\n",
    "Definition: The value below which 75% of the data falls.\n",
    "Purpose: Indicates the upper end of the middle 50% of the data.\n",
    "\n",
    "Max:\n",
    "Definition: The largest value in the column.\n",
    "Purpose: Shows the upper end of the data range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e64261",
   "metadata": {},
   "source": [
    "When df.dropna() is preferred:\n",
    "\n",
    "Scenario: You have a dataset where some rows have missing values, but you want to keep all columns.\n",
    "\n",
    "Example:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    'row_n': [0, 1, 2, 3],\n",
    "    'id': [1, 2, np.nan, 4],                # Missing value\n",
    "    'name': ['Alice', 'Bob', 'Charlie', np.nan],  # Missing value\n",
    "    'song': [11, np.nan, 12, 13],           # Missing value\n",
    "    'url': ['http://example.com/1', 'http://example.com/2', 'http://example.com/3', np.nan]  # Missing value\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "cleaned_df = df.dropna()\n",
    "print(cleaned_df)\n",
    "\n",
    "Result:\n",
    "row_n   id   name  song                       url\n",
    "0      0  1.0  Alice  11.0  http://example.com/1\n",
    "\n",
    "Why df.dropna() is Preferred:\n",
    "\n",
    "You retain all the columns in the DataFrame, and only rows with missing values are removed, so you have a complete dataset in terms of rows.\n",
    "This approach is preferred when you need to ensure that all columns are kept and only want to clean up rows with missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c246f4ba",
   "metadata": {},
   "source": [
    "When del df['col'] is preferred:\n",
    "\n",
    "Scenario: You have a dataset with some columns that have many missing values, and you want to remove these columns because they are not useful for your analysis.\n",
    "\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    'row_n': [0, 1, 2, 3],\n",
    "    'id': [1, 2, np.nan, 4],                # Missing value\n",
    "    'name': ['Alice', 'Bob', 'Charlie', np.nan],  # Missing value\n",
    "    'song': [11, np.nan, 12, 13],           # Missing value\n",
    "    'url': ['http://example.com/1', 'http://example.com/2', 'http://example.com/3', np.nan]  # Missing value\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "del df['id']\n",
    "del df['song']\n",
    "del df['url']\n",
    "\n",
    "print(df)\n",
    "    \n",
    "    \n",
    "    \n",
    "Result:\n",
    "    \n",
    "row_n       name\n",
    "0      0      Alice\n",
    "1      1        Bob\n",
    "2      2    Charlie\n",
    "3      3        NaN\n",
    "\n",
    "\n",
    "This approach is preferred when certain columns are not useful for your analysis due to a high proportion of missing values, and you want to streamline your dataset by removing those columns.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13fd52e",
   "metadata": {},
   "source": [
    "Applying del df['col'] before df.dropna() is important because it streamlines data cleaning by removing irrelevant or unnecessary columns with many missing values, which reduces the DataFrame's size and complexity. This optimization makes df.dropna() more efficient by focusing on a cleaner, smaller dataset, ultimately speeding up the processing and improving clarity by ensuring that only relevant columns are considered for cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faace3c",
   "metadata": {},
   "source": [
    "Approach\n",
    "Remove Columns with Missing Values: Use del df['col'] to delete columns that contain missing values. This ensures that these columns are not considered during the row cleaning process.\n",
    "\n",
    "Remove Rows with Missing Values: Use df.dropna() to drop any rows that still have missing values in the remaining columns.\n",
    "    \n",
    "Dataset Example:\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = {\n",
    "    'row_n': [0, 1, 2, 3],\n",
    "    'id': [1, 2, np.nan, 4],                # Missing value\n",
    "    'name': ['Alice', 'Bob', 'Charlie', np.nan],  # Missing value\n",
    "    'song': [11, np.nan, 12, 13],           # Missing value\n",
    "    'url': ['http://example.com/1', 'http://example.com/2', 'http://example.com/3', np.nan]  # Missing value\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "print(\"Before cleaning:\")\n",
    "print(df)\n",
    "\n",
    "\n",
    "del df['url']  # Removing 'url' column which has missing values\n",
    "\n",
    "\n",
    "cleaned_df = df.dropna()\n",
    "\n",
    "\n",
    "print(\"\\nAfter cleaning:\")\n",
    "print(cleaned_df)\n",
    "\n",
    "\n",
    "Justification:\n",
    "del df['url'] is used to delete columns that are not useful or have too many missing values. This simplifies the dataset and focuses on the remaining relevant columns.\n",
    "df.dropna() is applied to the cleaned DataFrame to ensure that only rows with complete data are retained.\n",
    "\n",
    "Reports\n",
    "Before:\n",
    "\n",
    "   row_n   id       name  song                       url\n",
    "0      0  1.0     Alice  11.0  http://example.com/1\n",
    "1      1  2.0       Bob   NaN  http://example.com/2\n",
    "2      2  NaN  Charlie  12.0  http://example.com/3\n",
    "3      3  4.0       NaN  13.0                      NaN\n",
    "\n",
    "After:\n",
    "\n",
    "   row_n   id   name  song\n",
    "0      0  1.0  Alice  11.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f244c44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the Penguins dataset\n",
    "df = sns.load_dataset('penguins')\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(df.head())\n",
    "\n",
    "# Group by 'species' and get descriptive statistics for 'flipper_length_mm'\n",
    "result = df.groupby('species')['flipper_length_mm'].describe()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec03e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "            count       mean        std   min    25%   50%    75%   max\n",
    "species                                                                  \n",
    "Adelie       73.0  200.914   14.06128  172.0  191.0  197.0  212.0  231.0\n",
    "Chinstrap    34.0  199.587   13.17970  181.0  193.0  197.0  208.0  227.0\n",
    "Gentoo       44.0  212.197   15.28439  185.0  203.0  214.0  223.0  231.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96753bf6",
   "metadata": {},
   "source": [
    "Explanation\n",
    "\n",
    "Loading the Data: \n",
    "The Penguins dataset is loaded using seaborn.load_dataset('penguins').\n",
    "\n",
    "Displaying the Data: \n",
    "df.head() shows the first few rows to get an idea of the dataset structure.\n",
    "\n",
    "Grouping and Describing:\n",
    "df.groupby('species') groups the dataset by the 'species' column (which indicates the species of penguin).\n",
    "['flipper_length_mm'] selects the 'flipper_length_mm' column (which measures the length of the penguin's flipper).\n",
    ".describe() computes the descriptive statistics for 'flipper_length_mm' within each species."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737fd452",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "\n",
    "Adelie:\n",
    "\n",
    "Count: 73 samples\n",
    "Mean flipper length: approximately 200.91 mm\n",
    "Standard deviation: approximately 14.06 mm\n",
    "Minimum flipper length: 172.0 mm\n",
    "25th percentile: 191.0 mm\n",
    "Median (50th percentile): 197.0 mm\n",
    "75th percentile: 212.0 mm\n",
    "Maximum flipper length: 231.0 mm\n",
    "Chinstrap:\n",
    "\n",
    "Count: 34 samples\n",
    "Mean flipper length: approximately 199.59 mm\n",
    "Standard deviation: approximately 13.18 mm\n",
    "Minimum flipper length: 181.0 mm\n",
    "25th percentile: 193.0 mm\n",
    "Median (50th percentile): 197.0 mm\n",
    "75th percentile: 208.0 mm\n",
    "Maximum flipper length: 227.0 mm\n",
    "Gentoo:\n",
    "\n",
    "Count: 44 samples\n",
    "Mean flipper length: approximately 212.20 mm\n",
    "Standard deviation: approximately 15.28 mm\n",
    "Minimum flipper length: 185.0 mm\n",
    "25th percentile: 203.0 mm\n",
    "Median (50th percentile): 214.0 mm\n",
    "75th percentile: 223.0 mm\n",
    "Maximum flipper length: 231.0 mm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81b808a",
   "metadata": {},
   "source": [
    "df.describe() gives a high-level view of data completeness and statistics for each column across the whole dataset.\n",
    "df.groupby(\"col1\")[\"col2\"].describe() provides insights into data completeness and statistics within each group defined by col1, which can highlight variations and patterns that differ by group.\n",
    "The count values in each method provide different insights based on whether you're looking at overall column data or segmented group data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4c86e3",
   "metadata": {},
   "source": [
    "A:chatgpt\n",
    "B:chatgpt\n",
    "C:chatgpt\n",
    "D:chatgpt\n",
    "E:chatgpt\n",
    "F:chatgpt\n",
    "G:chatgpt\n",
    "\n",
    "Link of Proof\n",
    "https://chatgpt.com/share/66e36e5c-a07c-800e-8f1f-ca2ffcee43dc\n",
    "    \n",
    "    \n",
    "For all instances, Chatgpt is much more time effecient in comparison to google search. Google searches are very ambiguous and indirect, and not necessarily the best option for finding mistakes for your specific situation. \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e06bb2",
   "metadata": {},
   "source": [
    "Yes, I have reviewed the course wiki-textbook and interacted with a ChatBot!\n",
    "\n",
    "Summary:\n",
    "\n",
    "Here's a summary of the prompts and their solutions:\n",
    "\n",
    "Forgetting to Include Imports:\n",
    "\n",
    "Issue: If you forget to include an import statement like import pandas as pd, you'll encounter a NameError when using the alias pd.\n",
    "Solution: Include the necessary import at the top of your code, e.g., import pandas as pd.\n",
    "Mistyping Filename:\n",
    "\n",
    "Issue: If you mistype a filename (e.g., \"titanic.csv\" as \"titanics.csv\"), you’ll get a FileNotFoundError.\n",
    "Solution: Ensure the filename is correct and matches the actual file. If necessary, correct the URL or filename.\n",
    "Using DataFrame Before Assignment:\n",
    "\n",
    "Issue: Using a DataFrame before it's assigned to a variable or using a mistyped variable name will result in a NameError.\n",
    "Solution: Ensure the DataFrame is properly assigned and that variable names are correctly spelled and used.\n",
    "Mistyping Chained Methods:\n",
    "\n",
    "Issue: Mistyping a method name in a chain of function calls (e.g., df.group_by instead of df.groupby) will lead to an AttributeError.\n",
    "Solution: Verify and use the correct method names in your chained function calls.\n",
    "Using Non-Existent Column Names:\n",
    "\n",
    "Issue: Using a column name that doesn’t exist (e.g., \"Sex\" instead of \"sex\" or \"Age\" instead of \"age\") will raise a KeyError.\n",
    "Solution: Ensure column names are correctly spelled and exist in the DataFrame.\n",
    "Omitting Quotes for Column Names:\n",
    "\n",
    "Issue: Forgetting to put column names in quotes will lead to a NameError because Python will interpret them as variables.\n",
    "Solution: Always use quotes around column names when specifying them as strings in operations like groupby and column selection.\n",
    "Removing Missing Data:\n",
    "\n",
    "Example Use Case: df.dropna() is used to remove rows with missing values, while del df['col'] is used to remove entire columns. Removing columns before handling missing data can improve performance and clarity.\n",
    "Example: Remove an unnecessary column first (del df['unnecessary_col']), then clean the data by removing rows with missing values (df.dropna()).\n",
    "Cleaning Data:\n",
    "\n",
    "Example Approach: First, remove unnecessary columns, then handle missing data.\n",
    "Summary of Example: Removing the unnecessary_col column simplifies the DataFrame, and applying df.dropna() ensures that the final dataset contains only complete rows.\n",
    "Each approach or solution is context-dependent and aims to address specific issues related to DataFrame manipulation and data cleaning.\n",
    "\n",
    "Link: https://chatgpt.com/share/66e36e5c-a07c-800e-8f1f-ca2ffcee43dc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7d2049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
